### Re-creating Shazam Music Algorithm from Scratch

- This is not a normal readme file. It's more of a note-taking readme where I'll jot down
  the details regarding what I am doing, how features I've implemented and what I learned
- The debugging processes, and as the project scales in complexity these notes will help me keep track of the things that are required to stay on course to completing this project.
- No AI assistance for code will be taken. Every single piece of code in this project will be thought thoroughly and written by me.

## 21st September 2025 - 3:07 p.m.

- Need to thing through the file structure for this project.
  - Let's write down the requirements that are needed to make this project.
    1. The Recording/Uploading of songs and clips
    2. The shazam magic 
    3. The Matching process
    4. The output 

- Can use FFMEG to process MP3 files and also record clips. 
- For the clip it's going to be something around 10 sec.
- But the song can vary from 2 mins to 5 mins, Therefore it's better to divide a song into chunks of 10 seconds, identify the pairs of frequency where amplitude changes rapidly and store them into the database.
- A challenge: what if the clip we have is in between two chunks of our song? 
- We can identify the interesting points in the clip;
- make chunks out of the points identified.
- generate hashes out of those chunks
- search the database for the hashes that match our clip hashes.
- return the songs with the max no. of hash matches.

- For songs we process each song in chunks, then we generate peak points,
then we batch the peak points into another chunk and generate a hash for that chunk and store it in the db.

- Another important thing to note is the time offset searching for the hashes. The hashes should be generated by keeping the time offset in mind, the lower the time offset of a pair of clip hash and song hash, the higher the probability of it being the correct song.

- For any song upload we are going to convert it into wav format. This ensures standardization of the whole process for the shazam algo.


## 27th September 2025 - 12:48 p.m - 1:06 p.m. 

- Will start by creating a record feature for the clip, a upload feature for the song, then a converter to wav for any format to wav and then wav processing for our Shazam Magic Pipeline.

- Step 1 : Installing FFMPEG (done)

- Step 2 : Figure out how to use FFMEG to Store a 10 second clip in memory. 
  - 28th Sept - 11:00 p.m. - 11:31 p.m.
           - Faced with a design choice now, Should I create a 10 sec buffer audio clip or store it properly inside a physical location. 
           - Buffer one seems to me the correct choice cause when the algo is going through the clip it can't listen to any other clip until the whole process is done.

- Step 3 : Now try creating a format change function using ffmeg to convert a given clip or song (used for both) into WAV (Next task)

## Winter Arc Begins - 1st Oct 2025 5:18 P.M (In mumbai ;)

- After a heavy look up into similar projects I now understand that the listening part of the project will be done on the client side and therefore I will have to implement the listening thing when I create the frontend of the project. 

- For backend we can assume that the frontend will be sending us audio data and then we will have to convert that into WAV format.

- So My first task is to complete the transformation of reading and writing raw audio data into WAV Format and saving them.

- In my understanding of the code base I learnt that FFMPED is a cross platform conversion library that is useful to convert files not record them. 

- We can use different libraries for recording and then convert it properly into different format using FFMPEG. It's like photoshop but in a code base.

- Main Package named "shazoom" ;)

- completed a convert function that takes in recording data sent by frontend and turns it into WAV format file and stores it and return the directory of the output file.

## 2nd Oct 2025 4:05 P.M (in mumbai)
- Now I need to create functions to extract data (metadata like sample rate, channels, bits per sample) from WAV files to use for our song recog algo.

- Creating wav.go, defining structure of WAV header (for writing and parsing raw WAV files)
  - WriteWAVHeader() for metadata
  - WriteWAVFile() for PCMData Extraction. (will use ffprobe [Part of FFMPEG] for metadata extraction)
  - ProcessRecording -> Will take the raw data provided by the frontend, will convert the file format to wav (build earlier), then will process the metadata and then create sample (float64) and return them for fingerprinting process.

- Alright completed the WAV header structure and writing to header. 

## 3rd Oct 2025 4:00 P.M
 
- Completed the wav file writing function and also the extraction of wav info from filepath function. (required during wav processing)

- Completed the extraction and normalization into float64 from raw PCM data (convert to signed 16 bit integer and then normalized into float64 [-1.0 to 1.0]) (required during wav processing)

- Next step is to complete the wav processing by adding the metadata extraction from raw file and then completing the whole flow in the final processRecording function. [6:07 p.m]

## 5th Oct 2025 8:30 P.M

- Completed the processing of an incoming file using ffprobe.
- Tested the function to see if the processing of the song details are happening correctly [passed]
- Now going to complete the processing of the song function that takes in a file and then process it correctly for the main shazam function